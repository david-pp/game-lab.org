---
layout: post
title: 每周回顾：少一点，再少一点
category : 每周回顾 
tags : []
date: 2015/08/28  18:00  +0800
--- 

信息爆炸，知识爆炸，知识量在以指数级上升，据说近几十年的知识量比过去人类整个历史积累的知识量都要多。而我们的大脑的进化速度，完全赶不上知识的增长，互联网时代给予我们太多便利去获得知识了，各种免费资源取之不尽，只要有求知欲，想学习什么可以轻而易举的获取各种资料，包括书籍、课件、视频等等。有时我就在想，人类的某一个领域，甚至某一领域的某一分支的知识会不会复杂到一个人穷尽一生也学习不完的地步？或许知识的分类会更多，会更精细，届时对于那些求知欲强大的人，企图一窥全貌，知道所有细枝末节几乎是不可能的事情了。貌似现在已经是这样了。

以上是在学习数据挖掘和机器学习时候，碰到很多新知识，随便google一下，又会扯出一堆信息，有感而发。自叹记忆力大不如前，看过就忘，还有悔不该在学校没有深入学几门数学。

<!--more-->

### 工作篇

游戏资料片上线一周，一次刷钱，一次大规模宕机，还有一些BUG。好在发现及时，及时解决。做游戏服务器，最怕的就是刷道具，刷经验，和大规模宕机，这次资料片都遇到了。没有了代码复审，再加上资料片当周，一口气外放的内容太多，也没有长时间小范围测试，出BUG是难免的。

最近一个月内，服务器端开发离职四位，送走了一个又一个战友，心里还是有点感慨的。不过，对于离职的同学来说也是好事，多经历一些就可以多学一点，往往在一个岗位上工作两年基本上就会达到瓶颈，发现没什么提高，所做的事情基本上都可以不需要太多的思考，顺手拈来了，久而久之，学习的热情也就没了，加之加班时间过长，离职难免。希望那些身边离职的战友们，有一个好的前程。爱学习，爱代码，也不要忘记我这个曾经的战友。有空，咱聚啊，哈哈。

### 学习篇

没营养的新闻，和口水文章看惯了，看数学和算法的速度也快了，结果是怎样的呢？现在周五，回想一下，基本上就剩下概念名词了，有些数学推导和算法过程完全一点印象都没了。下面只能根据记忆随意写了。本周大概学习了一下：


**基于实例的机器学习**

基于实例的机器学习，主要讨论了kNN(k-Nearest Neighbor)算法及其一个kd-tree实现。实例学习是相对于模型学习的，又称为懒惰学习(Lay Learning)，因为预测的过程需要用到学习用到的训练实例，而模型学习，如决策树学习，规则学习和SVM学习，都是靠训练集训练一个模型，然后使用模型去做预测，又称为迫切学习（Eager Learning）。

kNN中的关键是：距离定义，k值选择，和决策规则。kNN的思想是，利用实例之间的距离（可以是欧式距离，切比雪夫距离，也可以是其他，比如文本的相似度）来进行匹配。使用未知类型的实例，和所有训练样本实例计算距离，把最近的k个找出来，然后检查这个k个训练样本的类型（训练样本类型是已知的），占大多数的类型就是我们要预测的实例的类型。

可以看到当训练样本数量巨大的时候，每次遇到一个未知类型的实例都要遍历一遍，效率比较低下。所以可以预先使用训练集，构造一个kd-tree，kd意思是k dimension，kd-tree是一个对k维超平面的递归划分形成的一个树，每一个节点代表着某一个维度上的划分，预测的时候，从根节点开始检查，找到落在其中的超矩形，然后在回溯检查有没有更近的。
 

**集成学习**：

集成学习主要有三种类型：袋装（bagging）、提升（boosting）、堆栈（stacking）。主要学习了提升里面著名的AdaBoost算法（开始还以为前缀Ada和那位发现一个BUG的女程序员有关，结果Ada意思是Adaptive的意思，切勿望文生义）。

集成学习的目的是把基础分类器（如：决策树，SVM，Naive Bayes分类器等）集成后提高分类性能（提高查准率和查全率）。Bagging主要直接对基础分类器的预测结果加权求和，Boosting是把基础分类器串连起来，前一个预测错误的在下一里面的权值变大，预测正确的相应减少，从而提高整体的准确性。Stacking据说很少用到，多数机器学习书里面都没有提到它，其中Boosting方法用的比较多，AdaBoost据说效果不错。


**复习概率论**`

机器学习中朴素贝叶斯和贝叶斯网络在不懂概率统计的情况下，基本上就是看天书，满篇的概率公式推导，让人摸不着头脑。

找到大学时候的教材《概率论与数理统计教材》，恶补了一下概率论相关的知识，概率定义，加法定理，乘法定理，全概率公式，贝叶斯概率公式，随机变量，概率分布，概率密度，概率的数字特征，数学期望，方差，协方差，相关系数，大数定理，几何分布，超几何分布，二项式分布，泊松分布，正态分布。脑子里面的概念一股脑全写出来了。

也不能叫恶补，因为只是随便看了看，只知道个大概，若要用到还需要有针对地去研究。已经毕业多年的同学们，上面的概念还记得几个？

有人说概率统计时最实用的数学，是直觉的抽象描述。嗯，以我们国内的教材来看，完全尼玛就是先上公式，都不知道用于啥情况，然后解释一番，最后还一头雾水。总觉得，国内的数学书，适合用于复习，并不适合初学，因为它都是干货，不告诉你为什么，在什么情况下用，初学的话往往看一遍忘一遍，最后遇到实际问题，大眼瞪小眼就是不知从何下手。


**看了几篇关于游戏角色行为分析的论文**

- *Detection of MMORPG Bots Based on Behavior Analysis*

   MMORPG中机器人外挂的识别，基于两点假设：1> 外挂的特定类型的操作类型频率要远高于普通玩家；2> 外挂的操作主要集中在特定几种类型。分两阶段完成，第一阶段，根据假设判定外挂机，第二阶段，使用SVM训练已知的外挂数据，来预测未知的用户类型。

- *Detecting Real Money Traders in MMORPG by Using Trading Network*

   使用交易网络来识别MMORPG中打钱工作室的行为，本论文把游戏中的打钱工作室的角色分为三类：Earners, Collectors, Sellers。然后根据它们形成的交易网络来在整个交易网络中来识别此类角色。用到网络理论里面寻找社区的知识，不是特别了解，后续有需要，需要研究一下。

- *Visualization of Online-Game Players Based on Their Action Behaviors*

   提出两种在线游戏行为的可视化方法：CMDS和keyGrap。CMDS全称是Classical Multi Dimension Scale，是一种数据降维方式，在游戏中，把角色行为特征映射到二维坐标系中，然后直观地发现行为类似的聚类（说的这么容易，还是没看懂怎么个降维法，据说CMDS也不是你想降到2就能降到2的）；keyGrap是一个用于关键字网络分析的工具，在游戏中主要针对某些指定行为，来发现其他相关行为。


PS. 以上内容，都是自己的理解，可能有不对的地方。写下来是为了强化一下记忆和理解，否则周末一过，啥都想不起来了，现在经常这样，莫非真TM老了啊。


### 总结篇

上面林林总总列出的东西还是挺多的。但问题是，理解了多少？哪些可以不假思索地实际应用？想了想，除了kNN变遍历版的算法可以写出来，其它仅限于了解。

看得多了，思考的就少了，思考的少了，深度就不够，深度不够，知道有那么个东西顶个屁用，还是干不了事情。就像公司大Boss说的话一样“人一过三十就没创造力了”，那是因为见的多了，真正的创造力是利用手头有限的知识和资源去创造性地去做事情，关键还是要多思考，多实践。

一口气吃不成胖子会噎死人的，洋气点就是：Less is More！Less is More！

